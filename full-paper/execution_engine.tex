\section{\SeeDB Execution Engine}
\label{sec:optimizer}
\mpv{Short intro based on S3}

\subsection{Basic Implementation}
\label{sec:basic_implementation}

In the basic implementation, for each aggregate view stub, \SeeDB generates
a SQL query corresponding to the target
and comparison view, and issues
the two queries, one at a time, to the database.
It repeats this process for each aggregate view stub.
As the results are received, \SeeDB can compute the
distance between the target and comparison view
distributions, and identify the $k$ visualizations
with highest utility. 

Naturally, this basic implementation has many inefficiencies.
In a table with $a$ dimensions, $m$ measures, and $f$ aggregation functions, 
$2\times f \times a \times  m$ queries must be executed independently.  
As we show in Section~\ref{sec:experiments}, this can >100s for
large data sets (with hundreds of attributes and millions of rows).
These latencies are unacceptable for interactive use.
In this paper, we propose two different suites of optimizations to deal with these
inefficiencies.
The first type of optimizations, discussed in Section~\ref{sec:sharing_opt}, involve work {\em sharing},
i.e., combining view-computation queries as much as possible.
The second type of optimizations, discussed in Section~\ref{sec:in_memory_execution_engine}, involve {\em pruning}, where some aggregate views are not completely evaluated over the whole data set.
 The second suite of optimizations
are approximate, in that they, since they use utility estimates, there is a small likelihood that the returned visualizations may not have the highest utility.

\input{dbms_execution_engine.tex}
\input{in_memory_execution_engine.tex}