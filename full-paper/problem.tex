%!TEX root=document.tex


\section{Problem Statement}
\label{sec:problem_statement}

Given a database $D$ and a query $Q$, \SeeDB\ considers a number of views (i.e., aggregate queries) that
can be generated from $Q$ by adding relational operators.
For the purposes of this discussion, we will refer to views and visualizations
interchangeably, since it is straightforward to translate views into
visualizations automatically~\cite{DBLP:journals/cacm/StolteTH08}. 
For example, there are straightforward rules that
dictate how the view in Table~\ref{tab:staplerX} can be transformed to give a
visualization like Figure~\ref{fig:staplerX}.

% For this work, we classify attributes of a table into
% two types: {\it dimension attributes} and {\it measure attributes}. 
% Dimension
% attributes are attributes that are nominal, ordinal or numeric but with a small
% number of distinct values. 
% These are the attributes along which we can perform a group-by. 
% Measure attributes on the other hand are numeric attributes will a
% large number of distinct values. 
% We consider views where the dimension attributes are
% aggregated with respect to these measure attributes.



%Lastly, for simplicity, 
%we ignore {\em binning}: that is, given a view to be visualized,
%there are many ways of binning values to give the view. 
%For instance, if we have average profits per day, we can bin the days into
%months, into weeks, or into years.

Consider a database $D$ with a snowflake schema,
with dimension attributes $A$, measure attributes $M$, and potential
aggregate functions $F$ over the measure attributes.
Dimension attributes are either nominal, ordinal, or numeric,
but typically with a small number of distinct values;
these are the attributes along which we can perform a group-by.
Measure attributes are numeric attributes which take on a large number 
of distinct values; 
these are the ones that are typically aggregated.
We limit the class of queries $Q$ posed over $D$ to be
those that select one or more rows from the fact table, and denote the results
as $D_Q$. 
Given such a query $Q$, \SeeDB\ considers all views $V_i$ that perform a
single-attribute group-by and aggregation on $D_Q$. 
We represent $V_i$ as a
triple $(a, m, f)$, where $m \in M, a \in A, f \in F$, i.e., the view
performs a group-by on $a$ and applies the aggregation function $f$ on a measure
attribute $m$. We call this the {\em target view}.
%Thus, $V_i (D_Q)$ can be expressed as the following SQL query:
$${\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D_Q\  {\tt GROUP \ \ BY} \ a$$ 
Note that all such $V_i$ give rise to two-column results that can 
be readily visualized (e.g.
Table~\ref{tab:staplerX}). 
\SeeDB\ techniques can directly be used to recommend views that are
generated via multi-attribute grouping and aggregation; however,
for simplicity, we focus on two-column views. 


As discussed previously, \SeeDB\ determines
whether a view $V_i$ is interesting
by computing the deviation between the view applied to the selected data (i.e., $D_Q$) 
and the view applied to the entire database.
The equivalent view on the entire database $V_i (D)$ can be expressed as shown
below. We call it the {\em comparison view}. 
$${\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D\  {\tt GROUP \ \ BY} \ a$$
The results of both the above views are tables with two columns, namely $a$ and
$f(m)$. We normalize each result table into a probability distribution, such
that the values of $f(m)$ sum to $1$.
% over the various values of $a$ and the tables can be normalized into
%probability distributions for comparison. To convert each result table 
For our example in Table~\ref{tab:staplerX}, the probability distribution of
$V_i(D_Q)$, denoted as $P[V_i (D_Q)]$, is: (AT\&T: 180.55/538.18, Verizon:
145.50/538.18, T-Mobile: 122.00/538.18,  Sprint: 90.13/538.18). 
A similar
probability distribution can be derived for $P[V_i (D)]$.

Given a view $V_i$ and probability distributions for the
target view  ($P[V_i (D_Q)]$) and comparison view ($P[V_i (D)]$), the
{\em utility} of $V_i$ is defined as the distance between these two probability
distributions. Formally, if $S$ is a distance function,
$$ U (V_i) = S ( P[V_i (D_Q)], P[V_i (D)] )$$
The utility of a view is our measure for whether the target view is
``potentially interesting'' as compared to the comparison view:
the higher the utility, the more the deviation
from the comparison view, and the more likely the view is to be interesting.
% Computing distance between probability distributions has
% been well studied in the literature, and \SeeDB\ supports a variety of metrics
% to compute utility, including Earth Movers Distance~\cite{wikipedia-prob-dist}, 
% Euclidean Distance, Kullback-Leibler Divergence (K-L
% divergence)~\cite{wikipedia-KL}, and Jenson-Shannon
% Distance~\cite{wikipedia-JS,entropy-vis}. 
Computing distance between probability distributions has
been well studied, and \SeeDB\ supports all such
metrics that evaluate a distance between two distributions.
The metric may be supplied by the user, with their
application in mind.
Our current prototypes have the following in-built metrics
to compute utility:
\begin{denselist}
  \item {\bf Earth Movers Distance (EMD)}~\cite{wikipedia-prob-dist}: Commonly used to
  measure differences between color histograms from images, EMD is a popular metric for comparing
  discrete distributions. This is the default metric used in \SeeDB.
  \item {\bf Euclidean Distance}: The L2 norm or
  Euclidean distance considers the two distributions to be points in a high
  dimensional space and measures the distance between them.
  \item {\bf Kullback-Leibler Divergence}(K-L divergence)~\cite{wikipedia-KL}:
  K-L divergence measures the information lost when one probability distribution is used to approximate
  the other one.
  \item {\bf Jenson-Shannon Distance}~\cite{wikipedia-JS,entropy-vis}: Based on
  the K-L divergence, this distance measures the similarity between two probability distributions.
\end{denselist}
Finally, we note that while other definitions of the comparison views and
utility metrics are possible, for our initial exploration into 
visualization recommendations, we chose to focus on the intuitive definitions above.
In Appendix~\ref{sec:example-viz}, we perform a qualitative study of the EMD
metric showing that it returns interesting results on real-world datasets.
We can formally state the \SeeDB problem as follows:
% While we set the default \SeeDB\ distance metric as EMD (due to its simplicity),
% users can choose to use any of the distance metrics defined above. We note that
% the above definition of a view and its utility is merely one of many possible
% definitions and we choose this particular definition for simplicity and its
% intuitive nature. 
\begin{problem}
\vspace{-5pt}
Given an analyst-specified query $Q$ on a database $D$, a distance function $S$,
and a positive integer $k$, find $k$ views $V \equiv (a, m, f)$ that
have the largest values of $U(V)$ among all the views that can be represented
using a triple $(a, m, f)$, while minimizing total computation time.
\vspace{-5pt}
\end{problem}
Thus, \SeeDB\ aims to find the $k$ views (obtained by adding a single aggregate
 and group-by operator) that have the largest utility based on the function $U$.

While the problem definition above assumes that we have been provided with a
query $Q$ and we compare views on $Q$ with corresponding views on the entire
database $D$, the \SeeDB\ framework is agnostic to where the comparison
dataset is coming from and its contents. So the same formulation works for Use
Cases II and III discussed in Section \ref{sec:introduction}. 




%Trend in the subset of the data that deviates from the corresponding trend in
%the overall data.