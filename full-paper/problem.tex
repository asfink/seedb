	%!TEX root=document.tex
\section{Problem Statement}
\label{sec:problem_statement}

\reviewer {D1.2 I wonder what is really specific to visualizations. Indeed, a visualization
as defined by the authors seems to be a two column table (attribute,
measure). Is it usual to define visualizations this way?
}

\mpv{
	Aggregate summaries visualized as bar charts and column charts are in fact, extremely
	common visualizations, and hence are the first visualizations tackled by \SeeDB.
	The techniques we develop here are general and have possible applications 
	in traditional data mining. It would be interesting to explore these applications
	further.
}

Given a database $D$ and the subset of data selected by the analyst (via query $Q$), 
the goal of \SeeDB is to recommend visualizations of $Q$ that have high utility. 
\SeeDB (currently) focuses on recommending bar charts showing aggregate views of the 
data.
This choice is motivated by the fact that bar plots are the overwhelming
majority of visualizations created using visualization tools 
\cite{DBLP:journals/sigmod_record/MortonBGKM14}.

% The most common visualizations in real workloads of Tableau and ManyEyes 
% are bar charts \cite{DBLP:journals/sigmod_record/MortonBGKM14} showing aggregate views
% of the data. 
% Furthermore, the scale of data necessitates the visualization of aggregate summaries of
% data vs. individual records (e.g. average sales by state vs. sales of each store in the
% country).
% Consequently, \SeeDB (currently) focuses on this specific type of visualization.


\mpv{In this paper, we largely focus on a specific utility function that was introduced
in the previous section.
We discuss in Section \ref{}, how other distance metrics can be fit into our system
unchanged.}

% Due to the scale of data, most common visualizations show aggregate summaries of data
% as opposed to individual records (e.g. average sales by state vs. sales of each store 
% in every state).
% Moreover, these summaries are visualized as bar charts and column charts in the vast
% majority of cases~\cite{kristi}.
% Consequently, our current implementation of \SeeDB focuses on recommending bar and column
% charts that visualize aggregate summaries.
% Given a database $D$, associated schema $S$, and a user query $Q$, the goal
% of \SeeDB\ is to recommend visualizations of results of $Q$ with high utility. 
% As mentioned in Section~\ref{sec:introduction}, \SeeDB\ focuses on visualizations 
% that show aggregate summaries of data.

Let $D$ have a snowflake schema with 
dimension attributes $A$, measure attributes $M$, and potential
aggregate functions $F$ over the measure attributes. 
%Similar to cube aggregates, 
For visualization purposes, we assume that we can group $D$ along any of the dimension attributes $A$ 
and we can aggregate any of the measure attributes $M$.
Our system currently limits the class of queries $Q$ posed over $D$ to be single-table
selection (and optionally projection) queries.
We find that simple selection queries suffice for most visualization tasks.
For instance, in our illustrative example, $Q$ can select any subset of records from the
AppMetrics table. 
Adding projections to $Q$ serves to limit the the dimension and measure 
attributes used by \SeeDB in constructing visualizations.
We denote the result of $Q$ as $D_Q$.

% dimension attributes are either nominal, ordinal, or numeric,
% but typically with a small number of distinct values;
% these are the attributes along which we can perform a group-by.
% Measure attributes are numeric attributes which take on a large number 
% of distinct values; 
% these are the ones that are typically aggregated.
% We limit the class of queries $Q$ posed over $D$ to be
% those that select one or more rows from the fact table, 
% and denote the results as $D_Q$. 
% For instance, in a product sales table, $Q$ could select
% all tuples corresponding to transactions involving bicycles.
% Given query $Q$, \SeeDB\ considers all aggregate views 
% $V_i$ obtained by performing a grouping and aggregation on $D_Q$. 

Each visualization considered by \SeeDB can be translated into an aggregate
and grouping query on the underlying data.
% Since each visualization represents an aggregate summary of the underlying data,
% the visualization can be distilled into an aggregate and grouping query.
% Borrowing from the data cube literature~\cite{olap}, 
% we call these summaries aggregate {\it views}.
% where an aggregate view
% is the result of applying grouping and aggregation to a dataset.
Consequently, we represent visualization $V_i$ compactly as a triple $(a, m, f)$, 
where $m \in M, a \in A, f \in F$. 
The aggregate view performs a group-by on $a$ and applies the aggregation function $f$ 
to measure attribute $m$. 
While \SeeDB techniques can be used to recommend visualizations
generated via multi-attribute grouping and aggregation,
for simplicity, we focus on views generated by single attribute grouping. 

\reviewer{The range of queries that are supported is not clear. Specially in fig.3, in
the ``SQL'' tab, it seems that users can only define very simple selection
queries (where the selection is a simple conjunction of predicates). No
project, no joins, no difference, no grouping/agg. Is this correct? Why call
this SQL?}

\mpv{New interface only allows selections}

\reviewer {
	D2.1 The approach seems limited to simple queries of the form Select * from
aTable where someSelectionPredicates. It seems to me that it is quite a
limitation in the sense that the authors implicitly position their work in a data
warehouse exploration context (as per Section 2). I would like the authors to
comment that point. For instance, what about when the projection is not
select * but select aListOfAttributes?
}

\mpv{Do we need to defend why we support only simple queries? From other studies of
visualization tools, a significant portion of queries posed in these tools is 
limited to simple selection and projection tasks ~\cite{}.
Therefore, we have prioritized support for operations over more complex queries.}

\reviewer {
	D2.2 In the definition of $U(V_i)$: as $D_Q $contains a selection that D does not
have, how to ensure that the population of the two distribution is the same?
}

\mpv{
	This should only be in the reviewer response: the dataset under study $D_Q$ can be
	compared to various {\em comparison} datasets; by default, the comparison dataset
	is set to the full dataset $D$ (to observe overall trends), but can be set to any 
	other subset of data.
	Depending on the analytical task, one may want the two populations to be similar 
	(males and females in a given age group) or different (comparison of young adults to seniors). 
	Since the system has limited knowedlge about the exact analytical task, we provide 
	users with flexiblity to choose a comparison dataset.
}

% Note that all such $V_i$ give rise to two-column results that can 
% be readily visualized (e.g. Table~\ref{tab:staplerX}). 

% Consider a database $D$, and associated metadata $M(D)$, with a snowflake schema,
% with dimension attributes $A$, measure attributes $M$, and potential
% aggregate functions $F$ over the measure attributes.
% Dimension attributes are either nominal, ordinal, or numeric,
% but typically with a small number of distinct values;
% these are the attributes along which we can perform a group-by.
% Measure attributes are numeric attributes which take on a large number 
% of distinct values; 
% these are the ones that are typically aggregated.

% Given a database $D$ and a query $Q$, \SeeDB\ considers a number of views (i.e., aggregate queries) that
% can be generated from $Q$ by adding relational operators.
% For the purposes of this discussion, we will refer to views and visualizations
% interchangeably, since it is straightforward to translate views into
% visualizations automatically~\cite{DBLP:journals/cacm/StolteTH08}. 
% For example, there are straightforward rules that
% dictate how the view in Table~\ref{tab:staplerX} can be transformed to give a
% visualization like Figure~\ref{fig:staplerX}.

% For this work, we classify attributes of a table into
% two types: {\it dimension attributes} and {\it measure attributes}. 
% Dimension
% attributes are attributes that are nominal, ordinal or numeric but with a small
% number of distinct values. 
% These are the attributes along which we can perform a group-by. 
% Measure attributes on the other hand are numeric attributes will a
% large number of distinct values. 
% We consider views where the dimension attributes are
% aggregated with respect to these measure attributes.



%Lastly, for simplicity, 
%we ignore {\em binning}: that is, given a view to be visualized,
%there are many ways of binning values to give the view. 
%For instance, if we have average profits per day, we can bin the days into
%months, into weeks, or into years.

%  aggregate view $V_i$ by
% comparing data distribution in the query results to the data distribution of the underlying dataset.
% taking into consideration a variety of aspects, including
% user preferences, metadata, query data, background data, and context.
% For now, and for most of the paper, however, 
% That said, our techniques also seamlessly apply to a more general 
% class of distance metrics described in .

As outlined in Section \ref{sec:introduction}, \SeeDB determines the utility of 
visualizations via deviation; visualizations that show different trends in the query
result dataset (i.e. $D_Q$) compared to the full dataset (i.e. $D$) are said to have higher
utility.
Specifically, given a view $V_i$, the utility of $V_i$ is
computed as the deviation between the results of applying $V_i$ to $D_Q$ (the 
query data) and applying $V_i$ to the entire database (i.e., background data).
View $V_i$ applied to the results of $Q$ can be expressed as query $Q_T$. 
We call this the {\em target view}.
$$ Q_T\ =\ {\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D_Q\  {\tt GROUP \ \ BY} \ a$$ 
Similarly, view $V_i$ applied to the entire database $V_i (D)$ can be expressed as $Q_C$. 
We call this the {\em comparison view}. 
$$ Q_C\ =\ {\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D\  {\tt GROUP \ \ BY} \ a$$
The results of both the above aggregate views are summaries with two columns, namely $a$ and
$f(m)$. 
To ensure that all aggregate summaries have the same scale, we normalize each 
summary into a probability distribution (i.e. the values of $f(m)$ sum to $1$).
% over the various values of $a$ and the tables can be normalized into
%probability distributions for comparison. To convert each result table 
For our example in Table~\ref{tab:staplerX}, the probability distribution of
$V_i(D_Q)$, denoted as $P[V_i (D_Q)]$, is: (AT\&T: 180.55/538.18, Verizon:
145.50/538.18, T-Mobile: 122.00/538.18,  Sprint: 90.13/538.18). 
A similar probability distribution can be derived for $P[V_i (D)]$.

Given an aggregate view $V_i$ and probability distributions for the
target view  ($P[V_i (D_Q)]$) and comparison view ($P[V_i (D)]$), the
{\em utility} of $V_i$ is defined as the distance between these two probability
distributions. Formally, if $S$ is a distance function,
$$ U (V_i) = S ( P[V_i (D_Q)], P[V_i (D)] )$$
Higher the distance betwee the two distributions, more likely is the
visualization to be interesting and therefore higher the utility.
% The utility of a view is our measure for whether the target view is
% ``potentially interesting'' as compared to the comparison view:
% the higher the utility, the more the deviation
% from the comparison view, and the more likely the associated visualization is to be interesting.
Computing distance between probability distributions has
been well studied in the literature, and \SeeDB\ supports a variety of metrics
to compute utility, including Earth Movers Distance (default), 
Euclidean Distance, Kullback-Leibler Divergence (K-L
divergence), and Jenson-Shannon
Distance. 

\reviewer {
	D2.3 SeeDB supports a variety of metrics to compute utility, but only one of
them is tested. What is the impact of the metric used?
}
\mpv{
	We need to show experiments showing this.
}

We can formally state the \SeeDB problem as follows:
% Computing distance between probability distributions has
% been well studied, and \SeeDB\ supports a variety of metrics including
% to compute this distance.

% The metric may be supplied by the user, with their
% application in mind.
% Our current prototypes have the following in-built metrics
% to compute utility:
% \begin{denselist}
%   \item {\bf Earth Movers Distance (EMD)}~\cite{wikipedia-prob-dist}: Commonly used to
%   measure differences between color histograms from images, EMD is a popular metric for comparing
%   discrete distributions. This is the default metric used in \SeeDB.
%   \item {\bf Euclidean Distance}: The L2 norm or
%   Euclidean distance considers the two distributions to be points in a high
%   dimensional space and measures the distance between them.
%   \item {\bf Kullback-Leibler Divergence}(K-L divergence)~\cite{wikipedia-KL}:
%   K-L divergence measures the information lost when one probability distribution is used to approximate
%   the other one.
%   \item {\bf Jenson-Shannon Distance}~\cite{wikipedia-JS,entropy-vis}: Based on
%   the K-L divergence, this distance measures the similarity between two probability distributions.
% \end{denselist}
% Finally, we note that while other definitions of the comparison views and
% utility metrics are possible, for our initial exploration into 
% visualization recommendations, we chose to focus on the intuitive definitions above.
% In Appendix~\ref{sec:example-viz}, we perform a qualitative study of the EMD
% metric showing that it returns interesting results on real-world datasets.
% \mpv{Choice of metric should have been explained by this point}

% While we set the default \SeeDB\ distance metric as EMD (due to its simplicity),
% users can choose to use any of the distance metrics defined above. We note that
% the above definition of a view and its utility is merely one of many possible
% definitions and we choose this particular definition for simplicity and its
% intuitive nature. 
\begin{problem}
\vspace{-5pt}
Given a user-specified query $Q$ on a database $D$, a utility function $U$ as defined
above, and a positive integer $k$, find $k$ aggregate views $V \equiv (a, m, f)$ that
have the largest values of $U(V)$ among all the views $(a, m, f)$, 
while minimizing total computation time.
\vspace{-5pt}
\end{problem}
% Thus, \SeeDB\ aims to find the $k$ views (obtained by adding a single aggregate
% and group-by operator) that have the largest utility based on the function $U$.

% While the problem definition above assumes that we have been provided with a
% query $Q$ and we compare views on $Q$ with corresponding views on the entire
% database $D$, the \SeeDB\ framework is agnostic to where the comparison
% dataset is coming from and its contents. So the same formulation works for Use
% Cases II and III discussed in Section \ref{sec:introduction}. 





%Trend in the subset of the data that deviates from the corresponding trend in
%the overall data.