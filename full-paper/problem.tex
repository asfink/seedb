%!TEX root=document.tex


\section{Problem Statement}
\label{sec:problem_statement}

Given a database $D$, associated metadata $M(D)$, and a user query $Q$, the goal
of \SeeDB\ is to recommend visualizations of results of $Q$ with high utility. 
As mentioned in Section~\ref{sec:introduction}, \SeeDB\ focuses on visualizations 
that show aggregate summaries of data.
Borrowing from the data cube literature~\cite{olap}, 
we call these summaries {\it aggregate views}, where an aggregate view
is the result of applying grouping and aggregation to a dataset.

We let $D$ have a snowflake schema with 
dimension attributes $A$, measure attributes $M$, and potential
aggregate functions $F$ over the measure attributes. 
%Similar to cube aggregates, 
For visualization purposes, we assume we can group $D$ along any of the dimension attributes $A$ 
and we can aggregate any of the measure attributes $M$.
% dimension attributes are either nominal, ordinal, or numeric,
% but typically with a small number of distinct values;
% these are the attributes along which we can perform a group-by.
% Measure attributes are numeric attributes which take on a large number 
% of distinct values; 
% these are the ones that are typically aggregated.
We limit the class of queries $Q$ posed over $D$ to be
those that select one or more rows from the fact table, 
and denote the results as $D_Q$. 
For instance, in a product sales table, $Q$ could select
all tuples corresponding to transactions involving bicycles.
Given query $Q$, \SeeDB\ considers all aggregate views 
$V_i$ obtained by performing a grouping and aggregation on $D_Q$. 
We represent $V_i$ compactly as a triple $(a, m, f)$, where $m \in M, a \in A, f \in F$, 
i.e., the aggregate view 
performs a group-by on $a$ and applies the aggregation function $f$ to measure
attribute $m$. 
\SeeDB\ techniques can directly be used to recommend views that are
generated via multi-attribute grouping and aggregation; however,
for simplicity, we focus on views generated by single attribute grouping. 

% Note that all such $V_i$ give rise to two-column results that can 
% be readily visualized (e.g. Table~\ref{tab:staplerX}). 

% Consider a database $D$, and associated metadata $M(D)$, with a snowflake schema,
% with dimension attributes $A$, measure attributes $M$, and potential
% aggregate functions $F$ over the measure attributes.
% Dimension attributes are either nominal, ordinal, or numeric,
% but typically with a small number of distinct values;
% these are the attributes along which we can perform a group-by.
% Measure attributes are numeric attributes which take on a large number 
% of distinct values; 
% these are the ones that are typically aggregated.

% Given a database $D$ and a query $Q$, \SeeDB\ considers a number of views (i.e., aggregate queries) that
% can be generated from $Q$ by adding relational operators.
% For the purposes of this discussion, we will refer to views and visualizations
% interchangeably, since it is straightforward to translate views into
% visualizations automatically~\cite{DBLP:journals/cacm/StolteTH08}. 
% For example, there are straightforward rules that
% dictate how the view in Table~\ref{tab:staplerX} can be transformed to give a
% visualization like Figure~\ref{fig:staplerX}.

% For this work, we classify attributes of a table into
% two types: {\it dimension attributes} and {\it measure attributes}. 
% Dimension
% attributes are attributes that are nominal, ordinal or numeric but with a small
% number of distinct values. 
% These are the attributes along which we can perform a group-by. 
% Measure attributes on the other hand are numeric attributes will a
% large number of distinct values. 
% We consider views where the dimension attributes are
% aggregated with respect to these measure attributes.



%Lastly, for simplicity, 
%we ignore {\em binning}: that is, given a view to be visualized,
%there are many ways of binning values to give the view. 
%For instance, if we have average profits per day, we can bin the days into
%months, into weeks, or into years.

As discussed previously, \SeeDB\ determines the utility of an aggregate view $V_i$ by
comparing data distribution in the query results to the data distribution of the underlying dataset.
% taking into consideration a variety of aspects, including
% user preferences, metadata, query data, background data, and context.
% For now, and for most of the paper, however, 
While this utility metric is an example of a simple data-driven recommendation metric,
it plays an important role in recommendations when 
there is no prior history --- and therefore no user preferences
or understanding of context.
This special case is especially appropriate when the analyst
is not very familiar with a dataset and is analyzing it for the first time.
That said, in Section~\ref{sec:discussion}, we describe how our deviation-based
metric can, in fact, encompass a large number of data-driven utility metrics and
can be seamlessly extended to support other dimensions such as user preferences.
% That said, our techniques also seamlessly apply to a more general 
% class of distance metrics described in .

The utility function we focus on determines the utility of aggregate view $V_i$
by computing the deviation between the results of applying $V_i$ to the 
selected data (i.e., $D_Q$ or query data) and to the entire database (i.e., background data).
The aggregate view $V_i$ applied to the results of $Q$ can be expressed as query $Q_T$. 
We call this the {\em target view}.
$$ Q_T\ =\ {\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D_Q\  {\tt GROUP \ \ BY} \ a$$ 
Similarly, view $V_i$ applied to the entire database $V_i (D)$ can be expressed as $Q_C$. 
We call this the {\em comparison view}. 
$$ Q_C\ =\ {\tt SELECT \ } a, f(m) \ \ {\tt FROM} \  D\  {\tt GROUP \ \ BY} \ a$$
The results of both the above aggregate views are summaries with two columns, namely $a$ and
$f(m)$. 
To ensure that all aggregate summaries have the same scale, we normalize each 
summary into a probability distribution (i.e. the values of $f(m)$ sum to $1$).
% over the various values of $a$ and the tables can be normalized into
%probability distributions for comparison. To convert each result table 
For our example in Table~\ref{tab:staplerX}, the probability distribution of
$V_i(D_Q)$, denoted as $P[V_i (D_Q)]$, is: (AT\&T: 180.55/538.18, Verizon:
145.50/538.18, T-Mobile: 122.00/538.18,  Sprint: 90.13/538.18). 
A similar probability distribution can be derived for $P[V_i (D)]$.

Given an aggregate view $V_i$ and probability distributions for the
target view  ($P[V_i (D_Q)]$) and comparison view ($P[V_i (D)]$), the
{\em utility} of $V_i$ is defined as the distance between these two probability
distributions. Formally, if $S$ is a distance function,
$$ U (V_i) = S ( P[V_i (D_Q)], P[V_i (D)] )$$
The utility of a view is our measure for whether the target view is
``potentially interesting'' as compared to the comparison view:
the higher the utility, the more the deviation
from the comparison view, and the more likely the aggregate view (and its visualization) is to be interesting.
Computing distance between probability distributions has
been well studied in the literature, and \SeeDB\ supports a variety of metrics
to compute utility, including Earth Movers Distance (default), 
Euclidean Distance, Kullback-Leibler Divergence (K-L
divergence), and Jenson-Shannon
Distance. 
We can formally state the \SeeDB problem as follows:
% Computing distance between probability distributions has
% been well studied, and \SeeDB\ supports a variety of metrics including
% to compute this distance.

% The metric may be supplied by the user, with their
% application in mind.
% Our current prototypes have the following in-built metrics
% to compute utility:
% \begin{denselist}
%   \item {\bf Earth Movers Distance (EMD)}~\cite{wikipedia-prob-dist}: Commonly used to
%   measure differences between color histograms from images, EMD is a popular metric for comparing
%   discrete distributions. This is the default metric used in \SeeDB.
%   \item {\bf Euclidean Distance}: The L2 norm or
%   Euclidean distance considers the two distributions to be points in a high
%   dimensional space and measures the distance between them.
%   \item {\bf Kullback-Leibler Divergence}(K-L divergence)~\cite{wikipedia-KL}:
%   K-L divergence measures the information lost when one probability distribution is used to approximate
%   the other one.
%   \item {\bf Jenson-Shannon Distance}~\cite{wikipedia-JS,entropy-vis}: Based on
%   the K-L divergence, this distance measures the similarity between two probability distributions.
% \end{denselist}
% Finally, we note that while other definitions of the comparison views and
% utility metrics are possible, for our initial exploration into 
% visualization recommendations, we chose to focus on the intuitive definitions above.
% In Appendix~\ref{sec:example-viz}, we perform a qualitative study of the EMD
% metric showing that it returns interesting results on real-world datasets.
% \mpv{Choice of metric should have been explained by this point}

% While we set the default \SeeDB\ distance metric as EMD (due to its simplicity),
% users can choose to use any of the distance metrics defined above. We note that
% the above definition of a view and its utility is merely one of many possible
% definitions and we choose this particular definition for simplicity and its
% intuitive nature. 
\begin{problem}
\vspace{-5pt}
Given an analyst-specified query $Q$ on a database $D$, a distance function $S$,
and a positive integer $k$, find $k$ aggregate views $V \equiv (a, m, f)$ that
have the largest values of $U(V)$ among all the views $(a, m, f)$, 
while minimizing total computation time.
\vspace{-5pt}
\end{problem}
% Thus, \SeeDB\ aims to find the $k$ views (obtained by adding a single aggregate
% and group-by operator) that have the largest utility based on the function $U$.

% While the problem definition above assumes that we have been provided with a
% query $Q$ and we compare views on $Q$ with corresponding views on the entire
% database $D$, the \SeeDB\ framework is agnostic to where the comparison
% dataset is coming from and its contents. So the same formulation works for Use
% Cases II and III discussed in Section \ref{sec:introduction}. 




%Trend in the subset of the data that deviates from the corresponding trend in
%the overall data.