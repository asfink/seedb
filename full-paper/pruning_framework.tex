%!TEX root=document.tex

\section{View Pruning Framework}
\label{sec:pruning_framework}
% The previous section described techniques to
% batch and share computations across queries---however,
% if the number of queries is large, this can still 
% lead to high execution times.
Although it is possible to construct 100s of potential (aggregate)
visualizations for a typical dataset, only a fraction of these visualizations have high utility and are relevant to the user.
Most visualizations are low-utility and computational resources
are wasted in computing these visualizations.
% Moreover, only a fraction of the visualizations evaluated by
% \SeeDB are of high quality; most models have low utility and
% computational resources are wasted in computing these visualizations.
In this section, we describe our view pruning framework used to 
eliminate certain visualizations without complete evaluation.

\stitle{Basic Pruning Framework.}
\label{subsec:basic_framework}
As described in Algorithm \ref{}, once the \SeeDB optimizer 
generates an execution plan, the plan is executed 
on the subset of data corresponding to the
current phase.
Results of the current phase are then integrated into results
from previous phases to compute view utility and related statistics
(e.g. mean, standard deviation).
The \SeeDB pruner then takes the current set of utilities and applies
% the \SeeDB pruner kicks in at
% the end of each phase.
% Once the partition of data corresponding to the current phase has
% been processed, the \SeeDB results for each view query are integrated into results from previous phases.
% The \SeeDB execution engine computes the current view utility and
% related statistics (e.g. means, standard deviations) that are then fed to the \SeeDB pruner.
% The pruner in turn takes the current set of utilities and applies
a set of techniques to discard poorly-performing views and
optionally accept high-utility views as being in the top-$k$.
When only $k$ aggregate views remain (or $k$ are accepted), \SeeDB
can either return the views early (if approximate visualizations are permissible) or evaluate the views to completion.

\SeeDB implements different pruning schemes with tradeoffs in
accuracy and latency.
Our first pruning scheme applies traditional confidence-interval
techniques to bound utilities of views, while the second uses
multi-armed bandit allocation strategies to find top utility views.

\stitle{Confidence Interval-Based Pruning.}
\label{sec:confidence_interval}
This pruning scheme uses worst-case statistical confidence intervals to bound utility estimates obtained as \SeeDB
processes larger fractions of the underlying dataset.
Our pruning technique is similar to top-k based pruning 
algorithms developed 
in other contexts as described in ~\cite{DBLP:conf/pods/FaginLN01, 
DBLP:conf/vldb/IlyasAE04, DBLP:conf/ICDE/ReDS07}.

Pruning works as follows: at every point during execution, \SeeDB
maintains a running estimate of the mean utility $u_i$ for every view $V_i$ and a confidence interval around that mean, $u_i \pm c_i$.	
At the end of a phase, we use the estimates $u_i \pm c_i$ to prune low-utility views according to the following rule:
{\em If the upper bound of the utility of view $V_i$ is lesser
than the lower bound of the utility of $k$ or more views, then $V_i$ is discarded.}
To illustrate, suppose a dataset has four views $V_1$ to $V_4$ and we wish to find the top-$2$ views.
Further suppose that at the end of phase $p$,
$V_1$-$V_4$ have utility confidence intervals as shown in Figure \ref{fig:conf_interval}.
Views $V_1$ and $V_2$ have the highest estimates for utility so far.
Consider view $V_3$; we see that $V_3$'s confidence interval overlaps with the
confidence intervals of the current top views, making it possible
that $V_3$ will be in the final top views. On the other hand, the confidence
interval for $V_4$ lies entirely below the lowerbounds of $V_1$ and $V_2$.
Since we can claim with high probability
that the utility of $V_4$ lies within its confidence interval, it follows that
with high probability, $V_4$'s utility will be lower than that of both $V_1$ and
$V_2$, and it will not appear in the top-$2$ views.
We state the algorithm formally in
Algorithm~\ref{algo:ci_based_pruning}.

\begin{figure}[h]
\vspace{-10pt}
\centerline{
\hbox{\resizebox{8cm}{!}{\includegraphics[trim=10mm 100mm 55mm 35mm, 
clip=true]{Images/confidence_pruning.pdf}}}}
\vspace{-20pt}
\caption{Confidence Interval based Pruning}
\label{fig:conf_interval}
\vspace{-15pt}
\end{figure}

\reviewer {
	V5 is extraneous
}


% \papertext{Pseudocode for our pruning scheme can be found in our technical report~\cite{seedb-tr}.}

\begin{algorithm}
\caption{Confidence Interval Based Pruning}
\label{algo:ci_based_pruning}
\begin{algorithmic}[1]
\State viewsInRunning.sortByUpperbound()
\State topViews $\gets$ viewsInRunning.getTopK()
\State lowestLowerbound $\gets$ min(lowerbound(topViews))
\For {view $\not \in$ topViews}
\If {view.upperbound < lowestLowerbound}
\State viewsInRunning.remove(view)
\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

To obtain conservative bounds, we use {\it worst case} confidence intervals as derived from
the Hoeffding-Serfling inequality~\cite{serfling1974probability}.
The inequality states that if we are given $N$ values $y_1, \ldots, y_N$ in 
$[0, 1]$ with average $\mu$, and we have have drawn $m$ values without replacement, $Y_1, \ldots, Y_m$, 
then we can calculate a running confidence interval around the current mean 
of the $m$ values such that the actual mean of the $N$
is always within this confidence interval with a probability of $1 - \delta$:
\begin{theorem}
\label{thm:hs}

Fix any $\delta > 0$. For $1 \le m \le N-1$, define
{\small $$
\varepsilon_m = \sqrt{\frac{(1-\frac{m-1}N)(2\log \log (m) + \log(\pi^2/3\delta))}{2m}}.
$$
$$
\textrm{Then:} \ \   \Pr\left[ \exists m, 1 \le m \le N : 
  \left|\frac{\sum_{i=1}^m Y_i}{m} - \mu\right| > \varepsilon_m \right] 
\le \delta.
$$
}

\end{theorem}
In our setting, each $Y_i$ corresponds to an estimate of utility computed based on the
records seen so far. 


\stitle{Multi-Armed Bandit Pruning.}
\label{sec:multi_armed_bandit}
The \SeeDB pruning problem seeks to start with a large set of potential
visualizations and to rapidly narrow them at run-time to the set of 
visualizations with the highest utility.
Our second pruning scheme uses Multi-Armed Bandit (MAB)~\cite{bandits, AuerCF02, LaiR85} policies to identify top views.
In MAB, an online algorithm chooses from a set of alternatives (arms)
 over a sequence of trials to maximize reward; in our setting, alternatives correspond to various visualizations and reward corresponds
 to utility. 
We note that this is the first time that bandit strategies have been
applied to the problem of identifying interesting visualizations.

\techreport{The setting of MAB is as follows: a gambler is faced with several slot
machines (``one-armed bandit''s), each of which has an underlying 
(unknown) reward distribution. 
Every play results in a reward from the corresponding machine's
reward distribution.
The goal is to devise a {\it strategy} of which machine to play
at each turn in order to maximize the reward~\cite{bandits}.}
A recently-studied variation of MAB focuses on finding the arms with the highest
mean rewards~\cite{BubeckWV13, audibert2010best}.
Under certain assumptions, this variation is identical to the problem addressed by \SeeDB: our goal is find the views (arms) with the 
highest utility. \mpv {is it arms or bandits?}.
We therefore adapt the Successive Accepts and Rejects algorithm from \cite{BubeckWV13} 
to find arms with the highest mean reward. 
Algorithm~\ref{algo:mab_based_pruning} shows the pseudocode for our pruning technique.
% As before, the processing of the input table is divided into phases.
% In every phase, \SeeDB\ reads in new records and updates the distributions and utilities
% for every view in the running.
At the end of every phase, all {\it active} views are ranked in order of their utility means. 
We then compute two special differences between the utility means: $\Delta_1$
is the difference between the highest mean and the $k+1$st highest mean, and
$\Delta_n$ is the difference between the lowest mean and the $k$th highest mean.
If $\Delta_1$ is greater than $\Delta_n$, the view with the highest mean is
``accepted'' as being part of the the top-$k$ (and it no longer participates
in pruning computations).
On the other hand, if $\Delta_n$ is higher, the view with the lowest mean is discarded
from the set of views in the running.
\cite{BubeckWV13} proves that under certain assumptions about reward distributions,
the above technique identifies the top-$k$ arms with high probability.
\mpv{put guarantee?}

\reviewer{
	For the MultiArmed
Bandit pruning, it would be good to discuss whether
the assumptions of reward distributions would necessarily in this context.
}
\mpv{
	The MAB setting assumes that each trial samples from the same 
	underlying reward distribution, which is the reward distribution
	computed after processing all records. In our setting, however, 
	the underlying reward distribution changes gradually as we
	process more records and tends towards the {\em true} reward
	distribution.
	We assume that these changes to the distributions are small.
}

\begin{algorithm}
\caption{MAB Based Pruning}
\label{algo:mab_based_pruning}
\begin{algorithmic}[1]
\State viewsInRunning.sortByUtilityMean()
\State \{$\bar{u}_{i}$\} $\gets$ sorted utility means
\State $\Delta_1$ $\gets$ $\bar{u}_{1}$ - $\bar{u}_{k+1}$
\State $\Delta_n$ $\gets$ $\bar{u}_{k}$ - $\bar{u}_{n}$
\If {$\Delta_1$ < $\Delta_n$}
\State viewsInRunning.acceptTop()
\Else
\State viewsInRunning.discardBottom()
\EndIf
\end{algorithmic}
\end{algorithm}

\mpv{Guarantees from this technique?}


\subsection{Extension to Other Utility Metrics}

\mpv{should we say something here? Something like none of our
algorithms depend on the specific properties of EMD.
In fact, these techniques apply to any consistent estimator.
}

\mpv{
	Aditya: can you take a stab at this part?
}

Note that the two pruning schemes described below have guarantees
in other settings that do not directly carry over to our setting.
In our evaluation, we show that in spite of this limitation, the pruning schemes
work rather well in practice. 
We can, however, show that as we sample more and more, the estimated utility
$\hat{U}$ can be made to be arbitrarily close to $U$ for all aggregate views.
We can state our claim formally in the following lemma. 
\papertext{The proof based on 
Hoeffding's inequality can be found in the extended
technical report ~\cite{seedb-tr}.}
\techreport{The proof of this lemma is presented in Section \ref{sec:convergence}.}
% At a high level, the proof
% involves repeated applications of Hoeffding's inequality to
% upper and lower-bound $\hat{U}$ within $U$ along with terms 
% that tend to $0$ as the number of samples increases.

\begin{lemma}
Let the target and comparison visualizations
both have $m$ groups.
Let $\hat{U}$ denote our estimate of $U$ based on a uniformly random sample 
across all $m$ groups. 
Then, as the number of samples tends to $\infty$, $\hat{U} \rightarrow U$
with probability $1-\delta$, for as small $\delta$ as needed.
\end{lemma}